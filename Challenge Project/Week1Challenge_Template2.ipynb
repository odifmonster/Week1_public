{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XQDE8pPCpFRb"
   },
   "source": [
    "# Week 1 Challenge Project Template\n",
    "\n",
    "You are not required to use this template, but we are providing it for your reference to help get you started and stay organized!  We recommend that you define functions for each step to make it easier to track what's going on in the code (especially if different team members are working on different pieces of the project).\n",
    "\n",
    "Most of the functions provided are just examples!  Feel free to replace them with something better!  This is just a minimum working example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsZB_SGvp4mP"
   },
   "source": [
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as po\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "s9AtXQPkzC8j"
   },
   "outputs": [],
   "source": [
    "train_url = \"https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/allhypo.train.data.csv\"\n",
    "test_url = \"https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/allhypo.test.data.csv\"\n",
    "\n",
    "data_train = po.read_csv(train_url) \n",
    "data_test = po.read_csv(test_url)   # this will not have a 'class' column!\n",
    "\n",
    "# identify columns by what time of data they hold\n",
    "numeric_columns=list([\"Age\",\"TSH\",\"T3\",\"TT4\",\"T4u\",\"FTI\"])\n",
    "\n",
    "# categorical columns are everything else (minus 'class')\n",
    "categorical_columns = list(set(data_train.columns)-set(numeric_columns)-set(['class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sGKbG-eBqBjF"
   },
   "source": [
    "## 2. Format your class labels\n",
    "Turn multi-classes into binary classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rnp3nN9b6ZNw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40    2\n",
       "41    0\n",
       "42    0\n",
       "43    0\n",
       "44    0\n",
       "45    0\n",
       "46    0\n",
       "47    0\n",
       "48    0\n",
       "49    0\n",
       "50    0\n",
       "51    0\n",
       "52    0\n",
       "53    0\n",
       "54    0\n",
       "55    0\n",
       "56    0\n",
       "57    1\n",
       "58    1\n",
       "59    1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_class_labels(df):\n",
    "    \n",
    "    import re \n",
    "    \n",
    "    # regex the weird class labels out\n",
    "    regex_pattern = ( \"\\.\\|\\d+\")\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        # substitute instances of our regex_pattern for an empty string\n",
    "        new_class = re.sub(regex_pattern, '', row['class'])\n",
    "        df.loc[index,'class']=new_class\n",
    "    \n",
    "    # set all negative class labels to 0, all others to 1\n",
    "\n",
    "    df['class'] = df['class'].replace('negative', 0)                    \n",
    "    df['class'] = df['class'].replace('compensated hypothyroid', 1)     \n",
    "    df['class'] = df['class'].replace('primary hypothyroid', 2)         \n",
    "    df['class'] = df['class'].replace('secondary hypothyroid', 3)\n",
    "    \n",
    "    return df\n",
    "\n",
    "data_train = format_class_labels(data_train)\n",
    "data_train['class'][40:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split training into training and validation\n",
    "Choose what split you like (alternatively, you can do k-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train_2, data_val = train_test_split(data_train, test_size=0.20, random_state=0)\n",
    "\n",
    "while len(data_train_2['class'].unique()) < 4:\n",
    "    try:\n",
    "        data_train_2, data_val = train_test_split(data_train, test_size=0.20)\n",
    "    except:\n",
    "        print()\n",
    "\n",
    "data_train = data_train_2\n",
    "data_train['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean/format the data\n",
    "Note: removing rows is probably a bad idea because you won't be able to do this to the test data!  Try to come up with some clever ways to handle the \"?\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change all ?s to -1\n",
    "def handle_questions(df):\n",
    "    df.replace('?',0, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Make sure you do the same thing to train & val so the data is all formatted the same\n",
    "data_train = handle_questions(data_train)\n",
    "data_val = handle_questions(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uninformative_columns(df):\n",
    "    \n",
    "    drop_columns = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        # if this column has only one value, we can't learn anything from it\n",
    "        if(len(df[col].unique()) == 1):\n",
    "            drop_columns.append(col)\n",
    "            \n",
    "    return drop_columns\n",
    "\n",
    "\n",
    "# drop the uninformative features\n",
    "drop_columns = get_uninformative_columns(data_train)\n",
    "\n",
    "# Make sure you do the same thing to train & val\n",
    "data_train=data_train.drop(drop_columns,axis=1)\n",
    "data_val=data_val.drop(drop_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9QndSspU7lW4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "def format_data(df, numeric_columns):\n",
    "\n",
    "    # convert numeric columns from strings to numbers\n",
    "    df[numeric_columns] = df[numeric_columns].apply(po.to_numeric)    \n",
    "\n",
    "    categorical_columns = list(set(df.columns)-set(numeric_columns)-set(['class']))\n",
    "\n",
    "    # convert categorical columns to indicator (0,1) variables\n",
    "    for col in categorical_columns:\n",
    "        \n",
    "        try:\n",
    "            df[col] = po.get_dummies(df[col],drop_first=True)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Make sure you do the same thing to train & val\n",
    "print(data_train['class'].unique())\n",
    "data_train = format_data(data_train, numeric_columns)\n",
    "data_val = format_data(data_val, numeric_columns)\n",
    "print(data_train['class'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define and Train the Model\n",
    "You might want to consider having one process for training on one dataset and evaluating on another.  That way you can use the same code for your train/validation as you do for your train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier_predictions(data_train, data_predict):\n",
    "\n",
    "    feature_columns = list(set(data_train.columns)-set(['class']))\n",
    "\n",
    "    X_train = data_train[feature_columns]\n",
    "    y_train = data_train['class']\n",
    "    \n",
    "    X_val = data_predict[feature_columns]\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    clf = KNeighborsClassifier()\n",
    "    params = {\n",
    "        'n_neighbors' : range(1,11),\n",
    "        'weights' : ['uniform','distance'],\n",
    "        'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'leaf_size' : range(10,100,10)\n",
    "    }\n",
    "    optimal_clf = GridSearchCV(clf,params)\n",
    "    \n",
    "    optimal_clf.fit(X_train,y_train)\n",
    "    \n",
    "    y_proba = optimal_clf.predict_proba(X_val)\n",
    "    \n",
    "    return y_proba\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on validation data\n",
    "print(data_train['class'].unique())\n",
    "y_val_proba = my_classifier_predictions(data_train, data_val)\n",
    "y_val_proba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9980695  0.0019305  0.         0.        ]\n",
      " [0.6        0.36666667 0.03333333 0.        ]\n",
      " [0.25       0.         0.75       0.        ]\n",
      " [       nan        nan        nan        nan]]\n",
      "Confusion Matrix Metric:  nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# evaluate on validation set\n",
    "y_val = data_val['class']\n",
    "\n",
    "# This is exctly the first metric you'll be evaluated on!\n",
    "# Note: this will only work on the binary case -- let us know if you get to the multi-class case\n",
    "\n",
    "def cm_metric(y_true,y_prob):\n",
    "    \n",
    "    # predict the class with the greatest probability\n",
    "    y_val_predict = [np.argmax(y) for y in y_prob]\n",
    "\n",
    "    # calculate the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_val_predict, labels=[0,1,2,3])\n",
    "\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm_norm)\n",
    "    return sum(sum(np.multiply(cm_norm,np.array([[1, -1, -2, -4],\n",
    "                                                 [-4, 2, -1, -2],\n",
    "                                                 [-8, -2, 3, -1],\n",
    "                                                 [-16, -8, -4, 4]]))))\n",
    "\n",
    "print('Confusion Matrix Metric: ',cm_metric(y_val,y_val_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-7f8dfb29e2a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AUC: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[1;32m    533\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 534\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    316\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    317\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_val, y_val_proba[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC: ',roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.3f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apply to test data\n",
    "Once you're happy with your model, you should go through the same procedure again except:\n",
    "* train with ALL the training data (re-combine with training and validation)\n",
    "* test on test data (you won't be able to evaluate -- that's for us to do!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = \"https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/allhypo.train.data.csv\"\n",
    "test_url = \"https://raw.githubusercontent.com/BeaverWorksMedlytics/datasets/master/allhypo.test.data.csv\"\n",
    "\n",
    "data_train = po.read_csv(train_url) \n",
    "data_test = po.read_csv(test_url)   # this will not have a 'class' column!\n",
    "\n",
    "# format the wonky class labels\n",
    "data_train = format_class_labels(data_train)\n",
    "\n",
    "# deal with question marks\n",
    "data_train = handle_questions(data_train)\n",
    "data_test = handle_questions(data_test)\n",
    "\n",
    "# drop uninformative columns\n",
    "drop_columns = get_uninformative_columns(data_train)\n",
    "data_train=data_train.drop(drop_columns,axis=1)\n",
    "data_test=data_test.drop(drop_columns,axis=1)\n",
    "\n",
    "# format data\n",
    "data_train = format_data(data_train, numeric_columns)\n",
    "data_test = format_data(data_test, numeric_columns)\n",
    "\n",
    "# train and apply your classifier\n",
    "y_test_proba = my_classifier_predictions(data_train, data_test)\n",
    "y_test_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Submit your attempt!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wuexs1daLNBY"
   },
   "source": [
    "Once you've run on the test data, send a pickle file containing your predictions contained a pandas dataframe.  This pandas dataframe will contain two columns for your binary classifier (or 4 columns for the multiclass classifier) that looks like this (*pay attention to the column names!*):\n",
    "\n",
    "|   | 0 | 1   |\n",
    "|---|---|------|\n",
    "| 0 | $p_{0,0}$ | $p_{0,1}$|\n",
    "| 1 | $p_{1,0}$ | $p_{1,1}$|\n",
    "| 2 | $p_{2,0}$ | $p_{2,1}$|\n",
    "| ... | ... | ...|\n",
    "| N | $p_{N,0}$ | $p_{N,1}$|\n",
    "\n",
    "where $p_{i,j}$ corresponds to the probability of data point $i$ belonging to class $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "GkZOEgg3m3g1"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import pickle\n",
    "\n",
    "# create a pickle file (this will save to the Google cloud)\n",
    "prediction_pickle_path = 'teamname_week1_attempt1.pkl'\n",
    "prediction_pickle = open(prediction_pickle_path, 'wb')\n",
    "pickle.dump(y_test_proba, prediction_pickle)\n",
    "\n",
    "# download the pickle file and save it somewhere to your computer, and email it to \n",
    "#files.download(prediction_pickle_path)\n",
    "#prediction_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w66lpbB6Qv_M"
   },
   "source": [
    "# Moving to the Next Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-HZ12lht_so"
   },
   "source": [
    "For those that finish early, remember how I converted the class values into simply \"negative\" and \"positive\"? Now try tackling the multiclass classifier (predicting the different types of positive hypothyroid cases instead of simply negative or positive)! \n",
    "\n",
    "The same rules apply!  (Note: for the multiclass problem, the AUC calculation will be the micro-average over your classes.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lORJb8FOxHoS"
   },
   "source": [
    "(And for those that also finish the multiclass classifer, see Lyle for further instructions)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Challenge_Project_STUDENT.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
